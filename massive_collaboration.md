# Massive Collaboration
Massive collaboration exists all around us. Every day we live alongside a massive group of people that are mostly, although the media would certainly have us believe otherwise, civil and cooperative. By just living in a democratic society we are taking part in a massive collaboration. But this is what I would call a passive collaboration. We cooperate primarily by simply following the rules, by not actively doing anything to work against the peace. In this context the process in which we take part is one of maintenance. We work together to maintain a sort of cooperative homeostasis. But what about active participation in this same system? What form does this take? And what good does it do? Increasingly that is the question leaving a voting populace as disenfranchised as ever. Can one be actively involved? What percentage of the effort to be involved is actually helpful, actually effective? In our current system the answers to these questions always feel too tinged with optimism or faith in a certain system for the average cynic to bear. The answer is that we actively participate through our vote, which is ignored by our representatives with increasing frequency (see the previous section.) For those who want to do more, the answers to the question of how to be involved are frustrating. Donate money. Volunteer time. All things that simply feed into a broken system. Both of those answers are simply means to support a candidate, to pull votes one direction or another. Those answers boil down to "help us manipulate the voting system." This is not active participation in that sense that efforts result in output. Retreading to the notion of the decentralized system, this is a break. This is not part of the system, this is more the polishing of the housing in which the system runs. Then how can we be involved, hands on, with impact we can see, that we can track on an ongoing basis? The answer is that the system must change, it is time for the next evolution of the decentralized system of governance. Lucky for us, visionary programers, like Linus Torvalds already built all the tools that we need so that they could build things like the Linux operating system. We don't need to reinvent the wheel, we need only use it to maintain a different codebase: the US code.

Taking a step back, it seems relevant at this point to talk about what is meant when we say "massive." There is a whole separate book to be written about the difficulties of scale that arise when trying to wrap your head around the scale of communication that takes place in the world of computers, but it is important to try, because it will impact the ability to understand not only how certain collaborative tools came to be, but why they work, and the impact they could have. Certainly a large number of people are employed by the government. The size of the united states government in expenses and manpower dwarfs even large companies. Yet the number of people using the internet to communicate, the number of clicks, and the number of dollars spent on the internet put even the size of the world largest governments to shame. The size of the internet, and vastness of that communication is what we mean when we say "massive." Not hundred, not thousands, not even merely millions of people. Hundreds of millions. Google gets over three billion search queries A DAY. This is the level of traffic we are talking about. Linux, which I will discuss more in this section, is the collective work of over ten thousand programs, from one thousand different companies. Wikipedia has twenty eight million registered users. Moving forward with the idea of "massive collaboration" it is important to try to think of this scale. We are not talking about the coordination of the efforts of an office full of people, or even a team of a few hundred. We are talking about thousands, if not millions. 

Now lets look at the "collaboration" part of the title before diving into greater depth on the aforementioned tools. It is of value to look more closely at the passively collaborative system I mention above, to see the extent to which we are already steeped in cooperation and collaboration on a truly massive scale as we live in this democratic republic. We've begun with a look at the structure of the US Government, and its function in processing and producing code. As we work our way toward a discussion of possible future evolutions of this system it is important to step back a bit further to a broader question: What are laws? Why do we follow them? They guide our actions every day, but when was the last time you really stopped to think about what a law is? I don't mean, a bill becomes a law, so on and so on. I mean on a philosophical level, what is a law? Why do we have laws. The knee jerk answer is surely that we follow laws because otherwise we get in trouble. But, I'm going to go out on a limb here and guess that if you picked up a paper called "Crowdsourcing Democracy" or if you're reading this because you're interested in contributing to the project, that you follow lows because you believe that (mostly) they represent the right thing to do. If not that then at least you believe that laws represent the will of the people that these are the rules by which we agree to shape our behavior. Recently, in the course of a conversation about the state of democracy, and in response to what was probably a cynical comment on my part, a programmer friend said, "maybe you're right, but I also get a nice fuzzy feeling every time people pull over to let an ambulance pass. That's cooperation." At my core, like he, I'd also like to believe that everyone is pulling over for the ambulance because they know that it's a good thing to do, rather than because they otherwise might face legal consequences for failing to follow the law. Even aiming only for the middle ground, that most people are pulling over because they'd like you to do the same once they're the ambulance passenger, what we're talking about is cooperation, collaboration. So we can look at the laws as the guiding principles by which we know how not to get in trouble, or we can look at them as the tool that lets us know what everyone else is thinking with regards to appropriate behavior, or we can look at them as simply a reflection of how people would like themselves to be treated. Whether you are inclined toward the "carrot" or the "stick," it is undeniable that the purpose of most laws to to assure that everyone understands what is expected of them in order that our system of massive cooperation is maintained. For that is all that a democratic society is, in any form, meant to be: a system of massive cooperation. The US Code, that is, the collection of all laws by which be govern society is simply a program written, and modified over time through the system broken down in earlier chapter, to keep a huge number of people living in the same place, in cooperation.

It would seem, following from this way of looking at laws that the people demand a certain degree of input as to what these rules are. As it turns out, beyond casting a vote, the public has very little say in what actually ends up in a law. Given the extent to which society is itself a cooperative and collaborative effort, let us now take a look at the extent to which the current process of generating the rules is in fact collaborative. In the earlier section we looked quickly at the lawmaking process from the standpoint of decentralization, but what about lawmaking from the standpoint of collaboration? The people vote for representatives, and those representatives are tasked with writing, presenting, and defending the laws that they think are in the interest of the population they represent. In addition these representatives vote on every other law presented. While this does qualify as relatively decentralized, it seems a stretch to call this collaborative. Certainly it is not solitary, and it is collaborative in the sense that the population is working together to pick a representative, and then that representative's team is working together to write a bill. Additionally the representatives are working together to modify those bills to get something together that they can get voted through. Never mind that step, where congress "cooperates," what we're here to look at is the actual making of the law. To what extent is the making of the document that our representative takes to congress to try to pass, ostensibly because his or her constituents sent them, the result of actual collaboration? The answer is, it's not. Maybe they took some input in a town meeting, maybe they even took comments on the web, but ultimately most bills are written by five to ten staffers in a representative's office, and they are written to the specifications called for by the representative, or even the representative's political party. Until they hit the floor for debate in Congress the people don't get to see the bill, and even once they are available for debate there is little short of contacting your representative that can be done to proactively remedy a fault in that bill. This is not a collaborative process, and this is the break point for the decentralization. At this node, lawmaking is centralized. The only ones putting ideas on paper are those in the representatives office. 

The number of people enlisted to write a bill is as such out of necessity, just as less centralized systems functioned as they did out of the necessity of the time. But, as discussed previously, the evolution of communication technology and the ability to decentralize a system march hand in hand. Previously the notion of taking input on a bill from a massive number of people was simply not workable. There would be too much paper, too much reading, too much editing, too much work to keep the bill coherent. This is no longer a problem. We built the tools to solve these problems so we could manage massive teams, working on massive libraries of code. So finally, lets take a look at these tools.

The first thing to understand about programing is that it's simply writing. They call it "writing code." The language you are speaking is the language of computational problem solving, and the grammar depends on the programming language. But everything a computer does, action every picture, every tool, every status update can be distilled to letters an numbers. Those letters and numbers are arranged to form units of communication, those units are then arranged to perform a function, and those functions further organized to make a program. When your average person looks at a codebase it looks like nonsense, when a programer looks at it they see language. Looking at the whole thing at from this angle, you can see how it isn't much different from a paper, or a book, or, well, at this volume of content, an encyclopedia. If the code for Linux, a popular open source operating system, were printed on paper it would be in the neighborhood of one hundred thousand pages of text. This is a very large document. As you can imagine, a document this size takes a team to write. Take a moment and think to yourself how you would go about organizing this team. You'd probably break the things that needed to be written about into smaller chunks and then you'd give those chunks out to different smaller teams to oversee. If those chunk were still to big, they'd get split by the team into smaller chunks, overseen by another team, and so on, until we're down to a single writer working on a manageable  document. Sound familiarly like the decentralization we picked through in earlier sections? Such decentralization is not just unique to computing systems, or governments, it informs the organizational structure of any complex team. For an encyclopedia it's very easy to envision the branching tree structure of this organizational chart. Everyone works on their chunks, they are collected, most likely edited some to fit, and stitched together to make up the master document. In that way it's like wheel structure, there's still a master hub: the main document. When writing code programmers are dealing with a similar struggle. The codebase is massive, only certain chunks can be worked on at any time. No problem, just apply the same organizational structure as they other big document, the encyclopedia, right? Unfortunately, no. Well, in a sense, yes, but it gets complicated fast.

As Clay Shirky put it aptly in the TED talk reference in my introduction to this paper, "computers are notoriously inflexible." Computer are really good a processing code. But if that code is not correct, they are really bad at figuring out what the programmer meant to put there. Here we have the first hurdle to organizing a team to work on a document this large. Unlike the encyclopedia, when working on a program as complex as an operating system it's more like building a house. Yes, it is in essence a giant document made up of text, but each of those chunks of code depends on other chunks to function. If someone gets into the foundation codebase and makes some changes that cause that chunk of code to fail at its foundational job, then everything on top of it will also fail. To carry this to the encyclopedia analogy, if the entry for "Apple" had a typo in it, then the entry for "Elephant" would be inaccesible. As it relates to organizing a team to work this document we have a tricky situation. Because a team member can only handle so much on their plate tasks still need to be split up, but you can't simply mash all of the product back together after everyone has done their work. You can't do this because "Apple" and "Elephant" are actually materially dependent on one another. This independence breaks the standard organizational structure we were inclined to use. This hurdle is also shared by the law. In Shirky's talk he presents a graph of the interdependency of different sections of the United States Tax Code. This is not code in the sense of Linux, but it is code in the sense of the United States as an operating system. It is the set of rules by which our system of taxation operates. Similar to Linux, a change to one piece can break another piece. Similar to Linux the Tax Code is a very very long document. More than one person can reconcile. This brings us to the next hurdle.

Because of the above mentioned interdependencies there's also a massive coordination problem that arises when we try to organize and administer a team working on one of these documents. Here we're back to the house versus the encyclopedia. While teams can go off and work on their respective chunks of the final product, a massive interconnected codebase is more like the house in the sense that you have to be there to measure the space into which a window is going to fit. Even after you go away to build the window, and bring it back, any decent contractor will expect some "roughing in" to get that window to sit in the right place, and properly perform its functions. In the case of a codebase, and luckily for the programmers, they aren't stuck with a house they have to travel to to double check the window, but they are still dealing with a house. That is to say, as work goes on changes need to be made, and those changes need to be checked against the dependencies before a finished product can be declared. Because it isn't a house, and a codebase is simply a text document, programmers can take the house with them. This is a bonus, but it also gets us to the coordination problem. Now imagine a thousand houses, all with a slot for a window, and all needing that window to go in. It's easy to imagine that coordination of your team gets a bit messy when everyone has their own copy of the house, and they're working on more than windows, but lets just stick with the window for now. We need to get that window in there, everyone agrees on what a window looks like, and the basic function of the window, but there are many ways to skin that cat. You'll end up with some design that make the hole smaller to fit one type of window, others the commit to a larger window, windows that open out, slide up, and so on. Each of those window designs, of course, having an impact on other things like airflow through the house, what can go in the yard outside the window, how much wall space there will be left to paint, so on and so on once again. Little tweaks here and there, the "roughing in" that needs to happen after everyone gets their window built. Now all thousand people who took their copy of the house off to work come back with their different fixes and tweaks to other parts to make those fixes work, and what do you have? Not an encyclopedia, and maybe not even a house if the changes were all extreme enough. Now you a thousand different options for possible solutions to the problem: we need a window here. Again, here is where it makes sense that laws are called codes, as they again have in common this coordination problem. The laws need to be freely accessible, so everyone can read them and follow them. And as we begin to let our system of government chug along everyone has their ideas for how to fix the laws. Every team, made up of representatives and their staffers listens to some of those ideas, maybe forms their own, then takes their copy and goes off to work to get that idea in there, and they have exactly the same problem: everyone comes back with their various different solutions, and all of the "roughing in" that it takes to make the solution fit. Unfortunately, when installing a window wood is forgiving, laws are as unforgiving as computer code. The leeway for "roughing in" is minimal before a typo in the entry for "Apple" breaks the entry for "Elephant."

Independency and coordination are not problems unique to any of these situations, they are the reasons for any sort of hierarchical organizational structure. These struggles are the reason that governments are so large, and companies like Microsoft are so big. The larger the organizational diagram gets in order to mitigate the effect of these hurdles the more managers that need to be put in place to keep everything from breaking. Now lets introduce another quirk that will help understand the evolution of the tools to which this is an extended introduction: the open source movement. The "source" in open source refers to the code. The code underlying a program, which I have to this point called the "codebase" is sometimes called the source code. The "open" source model is a model of software development in which the source code for a piece of software is publicly available. Anyone can download the code, anyone can modify on this code, and anyone who does so agrees to a license which stipulates that their work will also be public and freely edited by anyone else agreeing to the same "open" license. This model exists in opposition to a "closed" source model, which is that favored by anyone or any company who wants to keep their software proprietary, usually so it can be leveraged for profit, sometimes for security reasons. Regardless of the motivation for an open versus closed model, the open model increases the difficulty brought about by the problems of interdependency and coordination by factors. Imagine all of the struggles I mentioned above, in an open system. Take away the management gatekeeper that might oversee the large and complicated system required to keep all of this dependency and coordination from cascading into full on failure. Now not only are week looking at those two problems, but we just invited anyone that wants to to hop onboard with their edits, with their input. Sounds crazy, right? Sounds like an unmanageable mess, right? Well, we have this movement to thank for the tools that I hope we can now turn toward government, to make our system truly one of the people. People like Linus Torvalds, the programmer who started Linux (and from which it draws its name,) believed that open source, and massive collaboration on complicated projects would be the best way to facilitate projects of the scale needed for technology to continue to advance. In the face of the extent to which all of seems so difficult to manage the open source movement took hold, and ultimately this same movement developed the tools it needed to help itself persist. Tools like Git, and Stack Overflow.

Faced with the difficulties and complications mentioned above the open source programmers, instead of abandoning the effort, built tools to help solve these problems. The first of these was a program, or a site really, called "Git." Git is what we call a "version control system." Broken down, that's quite literally, a system by which all of the different version of a codebase that have been checked out to be worked on, like we talked about above, are controlled. Git was literally developed by the same people that were working on Linux because they saw a looming coordination crisis as numbers grew, and maintenance of a stable codebase via email was increasingly difficult. They had used similar systems before buckling down to build Git, but most of them were costly, and still suffered from a degree of lag in coordination that made it difficult for multiple to people to work simultaneously. Part of the concern was not just that coordination is handled, but that collaborative effort is maximized. In a movement like the open source movement you have a lot of people working for free, simply because think they can help, or they want to test out any idea at a solution for a problem. When people are working for free, burning their time in inefficiency is foolish. Git works through a "repository" system.  A repository, or a repo, is a folder that contains everything you need to run a computer program. When running Git, any change made to that repo is given a unique identifier. When software is open source anyone can also freely make a copy of the full repo, they call this "forking", or they can start their own "branch" of changes. Each of those also gets it own identifier, and each of those changes, along with the tag to identify that change is added to the repo. As a program continues to take shape, and code is added, removed, written, and rewritten, every single set of edits gets its own ID, and all of this is included in the repo. When using a version control system a repo is ultimately not just a giant document with thousands of pages of code like I described above, but it is as also a canonical record of every change that has ever been made to that code base, who made that change. In that sense it is the code, as well as the history of every state in which that code has ever existed. You can see from the terminology used, words like "fork" and "branch" it is almost easier to visualize a codebase using Git like less of a long long document, and more of a tree. Each change is a branch, somewhere something was done differently. It's not just a program, but a record of a decisions and work that got the team to the final product. 

When it comes to coordination and collaboration the use of a version control system has a number of benefits. To begin with, many people can work on the same codebase without catastrophically breaking anything, while still giving them the access they need to the whole interdependent system that they need to make sure nothing will break. They can fork the whole codebase, run the program, make their changes, and see if it still work, locally. If it doesn't they can keep working at fixing it, if it does they can submit these edits, what's called a "commit." This means the edits have been added to the Git tracking registry, associated with your ID. After this those edits can be submitted to the main branch to be added to the "master" repo. Because the system is based not around full code documents, and instead around changes, things can happen much faster. The system is able to identify only the places where the code is now different, and present those changes to what is usually a lead programmer who okays them to go into the main codebase. Instead of having to send the whole document back to the lead programmer, the only thing that shows up, in a view where it's quite easy to see the changes, are the changes themselves. The lead programmer can then add those to the main codebase, if everyone else using the system then sys to the main repo, they have the updated code. This is the first big benefit, by tracking changes, instead of completed documents the amount of information that needs to be sent back and forth is considerably decreased. All that needs to be sent is the tracking data, and the changes, instead of a whole, now different, copy of the program. Next the canonical nature of the version tracking makes it so that the code is forever backed up. Here it helps to imagine the tree structure I alluded to earlier. If the lead programmer checks out all the changes, and they seem good in theory but in practice they break the program, fixing this mess is as simple as backing up to the last fork in the tree. Because the repo is not the just the program, but the record of all the changes ever made, then we can just back up the last place the program worked, and try again. The ability to do this also facilitated the massive collaboration. With so many people working on a project there are bound to be conflicts, the ability to simply go back in time to before a conflict broke things is important, and easily facilitated by version control software like Git. What's more, each of the changes is associated with the person who made that change. This means that a team member who regularly submits changes that don't work can be identified, helped, or dismissed from the project in the worst case. Luckily the the ability to roll back errors so easily, learning how to improve as a programmer becomes much more about practice, and much less about theory. 

Tools like Git not only open up a world in which large scale collaboration on programs as vast as Linux are possible, but it also reduces the barrier to entry. In an open source repo the code is freely accessible, and version control allows you not only to keep up with he work of others, but to compare work of others, easily incorporate the work of others, and maybe most importantly try and fail without consequence. Add in that you can write code with the most basic of computers, and you have a perfect scenario for education. It is difficult to learn to build a house, you have to leave a trail of poorly hewn boards in your wake. This gets expensive. When working on a program you can catastrophically wreck the codebase and simple roll back to the last time that it work. You can truly learn by doing, the loss of time as your own consequence. Because of this there has sprung up a whole host of tools to help with learning and to help with problem solving. In addition to resources like the now ubiquitous Wikipedia, numerous question and answer sites have sprung up solely to connect people with very specific questions, with people who have the answers, and are willing to take the time to explain. Such sites seem most frequently to be used to convince the general population that they are dying of some disease (Yahoo Answers, I'm looking at you,) but mostly they fill in the gaps where broader resources like Wikipedia do not have the answers. One such place where very specific question arise is the world of programming, and one such tool that has sprung up to answer those questions is Stack Overflow.

Stack Overflow is named for a software error in which a variable is bigger, in terms of characters, than the space it is meant to occupy. It's usually cause by some sort of accidental recursive operation that if allowed to run keeps adding to that variable until that number is so large there aren't enough characters allocated. Stack Overflow, the site, is actually a question and answer website devoted to the broad topic of computer programming. Loosely I would guess that the name was pulled from the frustration of running into something like a stack overflow, and the desire to ask someone for help if you are unable to solve it. Most likely the name was chosen because it sounds cool. Regardless, the website has a number of features that have made it a remarkable resource for programming knowledge. Stack Overflow was certainly not the first question and answer site to pop up, or even the first devoted to programming, but the creators of Stack Overflow added a few unique features. First, answers, and questions, can be voted on by users. This means that the most common questions, and the most clear questions rise to the top, additionally the answer to the questions end up sorted by which answer is the correct solution to whatever the coding hurdle was that lead to the question. Second there is a "reputation" system. This system awards points for up votes on both questions and on answers. Users of Stack Overflow end up with reputation rankings based on both how well the ask question, but also how well the answer them. As a user climbs in reputation they are also given increased permissions and responsibilities within the community. This means they gain ability to edit questions, delete answers, and so on. Included is the ability to close out a question. This is the final feature unique to Stack Overflow. When a question has a satisfactory answer, that is, the solution provided fixes the problem, then the question is closed. It remains in the system, so it shows up in search, but there is no longer any voting. As a resource this answer is considered a functional solution to the problem. Over time this system has created an extremely useful resource on a number of levels. Not only are most questions one might have with regards to programming likely already answered somewhere on Stack, but you can look at a programmers reputation number to get a decent sense of their standing on the cutting edge of computers. I say the cutting edge because there's no chance to gain points answering the old questions, so points are picked up these days answering and posting questions in the spaces where people are doing new things. This side effect of the system of merit based ranking is actually another feature of such a system that may not be unique to Stack Overflow so much as programming. If you want to get points, you need to work on new things.

There are numerous other compelling 