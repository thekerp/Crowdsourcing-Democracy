# Massive Collaboration
Massive collaboration exists all around us. Every day we live alongside a massive group of people that are mostly, although the media would certainly have us believe otherwise, civil and cooperative. By just living in a democratic society we are taking part in massive collaboration. But this is what I would call a passive collaboration. We cooperate primarily by simply following the rules, by not actively doing anything to work against the peace. In this context the process in which we take part is one of maintenance. We work together to maintain a sort of cooperative homeostasis. But what about active participation in this same system? What form does this take? And what good does it do? Increasingly that is the question leaving a voting populace as disenfranchised as ever. Can one be actively involved? What percentage of the effort to be involved is actually helpful? Actually effective? In our current system the answers to these questions always feel too tinged with optimism or faith in a certain system for the average cynic to bear. The answer is that we actively participate through our vote, which is ignored by our representatives with increasing frequency (see the previous section.) For those who want to do more the answers to the question of how to be involved are frustrating. Donate money. Volunteer time. All things that simply support the system. Both of those answers are simply means to support a candidate, to pull votes one direction or another. Those answers boil down to "help us manipulate the voting system." This is not active participation in the sense where efforts result in output. Retreading to the notion of the decentralized system, this is a break. This is not part of the system, this is more the polishing of the housing in which the system runs. Then how can we be involved, hands on, with impact we can see? Impact we can track on an ongoing basis, like sports scores, or retweets? The answer is that the system must change, it is time for the next evolution of the decentralized system of governance. Lucky for us, visionary programers, like Linus Torvalds already built all the tools that we need so that **they** could build things like the Linux operating system. We don't need to reinvent the wheel, we need only use it to maintain a different codebase: the US code.

Taking a step back, it seems relevant at this point to talk about what is meant when we say "massive." There is a whole separate book to be written about the difficulties of scale that arise when trying to wrap your head around the quantity of communication that takes place in the world of computers. Still, it is important to try, because it will impact the ability to understand not only how certain collaborative tools came to be, but why they work and the impact they could have. Certainly a large number of people are employed by the government. The size of the United States government in expenses and manpower dwarfs even large companies. Yet the number of people using the internet to communicate, the number of clicks, and the number of dollars spent on the internet put even the size of the world's largest governments to shame. The size of the internet, and **that** vastness of communication is what we mean when we say "massive." Not hundreds, not thousands, not even merely millions of people. Hundreds of millions. Billions. Google gets over three billion search queries A DAY. This is the level of traffic we are talking about. Linux, which I will discuss more in this section, is the collective work of over ten thousand programers, from one thousand different companies. Wikipedia has twenty eight million registered users. So this is the scale we are dealing with here. Moving forward with the idea of "massive collaboration" it is important to try to think of this scale. We are not talking about the coordination of the efforts of an office full of people, or even a team of a few hundred. We are talking about millions.

Now lets look at the "collaboration" part of the title before diving into greater depth on the tools we're talking about here. It is of value to look more closely at the passively collaborative system I mention above, to see the extent to which we are already steeped in cooperation and collaboration on a truly massive scale as we live in this democratic republic. We've begun with a look at the structure of the US Government, and its function in processing and producing code. As we work our way toward a discussion of possible future evolutions of this system it is important to step back a bit further to a broader question: What are laws? Why do we follow them? They guide our actions every day, but when was the last time you really stopped to think about what a law is? I don't mean, 'a bill becomes a law, so on and so on.' I mean on a philosophical level, what is a law? Why do we have laws. The knee jerk answer is surely that we follow laws because otherwise we get in trouble. But, I'm going to go out on a limb here and guess that if you picked up a paper called "Crowdsourcing Democracy" or if you're reading this because you're interested in contributing to the project, that you follow laws because you believe that (mostly) they represent the right thing to do. If not that then at least you believe that laws represent the will of the people that these be the rules by which we agree to shape our behavior. Recently, in the course of a conversation about the state of democracy, and in response to what was probably a cynical comment on my part, a programer friend said, "maybe you're right, but I also get a nice fuzzy feeling every time people pull over to let an ambulance pass. That's cooperation." At my core, like he, I'd also like to believe that everyone is pulling over for the ambulance because they know that it's a good thing to do. Not simply because they otherwise might face legal consequences for failing to follow the law. Even aiming only for the middle ground, that most people are pulling over because they'd like you to do the same once they're the ambulance passenger, what we're talking about is cooperation, collaboration. So we can look at the laws as the guiding principles by which we know how not to get in trouble. We can look at them as the tools that let us know what everyone else is thinking with regards to appropriate behavior. Or, we can look at them as simply a reflection of how people would like to be treated themselves. Whether you are inclined toward the "carrot" or the "stick," the material function of "a law," you know, all those words, the actual characters, the code; the purpose of most laws is to tell us what the rules are so we can all get along. For that is all that a democratic society is, in any form, meant to be: a system of massive cooperation. The US Code, that is, the collection of all laws by which be govern society is simply a program. One written, and modified over time through the system broken down in earlier chapters. Written to keep a huge number of people living in the same place, in cooperation.

It would seem, following from this way of looking at laws that the people demand a certain degree of input as to what these rules are. As it turns out, beyond casting a vote, the public has very little say in what actually ends up written in the code. Given the extent to which society is itself a cooperative and collaborative effort, we should take a look at how "collaborative" the process of generating that code actually is. In the earlier section we looked quickly at the governmental processes from the standpoint of decentralization, but what about lawwriting from the standpoint of collaboration? The people vote for representatives, and those representatives are tasked with writing, presenting, and defending the laws that they think are in the interest of the population they represent. The piece of paper they wave the whole time is covered in code. Ultimately, these representatives vote on every other bill presented, and those that pass become law. That new program, for whatever, is integrated. A computer programer would say it's been "committed" to the codebase. This absolutely does not clear the bar for "massive" collaboration. This isn't internet sized collaboration. Certainly it is collaborative in the sense that the population is working together to pick a representative. But after the election process this representative's team is working together to write a bill. To be very clear: this team is probably 5 lawyers in a conference room. They are the ones writing the code. Different representatives' teams are working together to combine and modify. You know, do political stuff. Never mind that step. That's all lawyers talking to lawyers. What we're here to look at is the actual writing of the code. How massively collaborative, how "democratic" is the process of writing the words that sit on the piece of paper your representative is pointing to? The answer is, it's not. Maybe they took some input in a town meeting, maybe they even took comments on the web, but ultimately most bills are written by five to ten staffers in a representative's office, and they are written to the specifications called for by the representative. Until they hit the floor for debate in Congress the people who elected the representative don't get to see the bill, and even once they are available for debate there is little short of contacting your representative that can be done to proactively remedy a fault in that bill. This is not a collaborative process on the scale of the internet. This is the break point for the decentralization. This is not decentralized. On any level. At this node, lawmaking is centralized. The only ones putting ideas on paper are those in the representatives office. 

I'm not saying we should all get to write the laws, but I want to put in your minds the idea that we should at least get to know what's in them before it's too late for us to do anything. The number of people enlisted to write a bill works the way it does out of necessity, just as monarchies functioned as they did out of the necessity of the time. But, as discussed previously, the evolution of communication technology and the ability to decentralize a system of communication march hand in hand. Previously the notion of taking input on a bill from a massive number of people was simply not workable. There would be too much paper, too much reading, too much editing, too much work to keep the bill coherent. This is not really a problem, we've already figured out how to do things like this at the scale of the internet. We built the tools to solve these problems so we could manage massive teams working on massive libraries of code, so computers can do what they do today.

## The Tools

The first thing to understand about programing is that it's simply writing. They call it "writing code." The language you are speaking is the language of computational problem solving, and the grammar depends on the programming language. But everything a computer does, every action, every picture, every tool, every status update can be distilled to letters and numbers. Those letters and numbers are arranged to form units of communication, those units are then arranged to perform a function, and those functions further organized to make a program. When your average person looks at a codebase it looks like nonsense, when a programer looks at it they see language. Looking at the whole thing from this angle, you can see how it isn't much different from a paper, or a book, or, well, at this volume of content, an encyclopedia. Let's go with an encyclopedia. If the code for Linux, a popular open source operating system, were printed on paper it would be in the neighborhood of one hundred thousand pages of text. This is a very large document. As you can imagine, a document this size takes a team to write. Take a moment and think to yourself how you would go about organizing this team. You'd probably break the things that needed to be written about into smaller chunks and then you'd give those chunks out to different smaller teams to oversee. "You're in charge of the letter 'T'" and so on. If those chunks were still too big, they'd get split by the team into smaller chunks, overseen by another team, and so on, until we're down to a single writer working on a manageable document. In an encyclopedia we're now down to, "you go write an entry about Turtles." Sound familiar? Maybe like the decentralization we picked through in earlier sections? Such decentralization is not just unique to computing systems, or governments. It informs the organizational structure of any complex team. For an encyclopedia it's very easy to envision the branching tree structure of this organizational chart. Everyone works on their chunks, they are collected, most likely edited some to fit, and stitched together to make up the master document. In that way it's like wheel structure, there's still a master hub: the main document. When writing code programers are dealing with a similar struggle. The codebase is massive. Only certain chunks can be worked on at any time. No problem, just apply the same organizational structure as the other big document, the encyclopedia, right? Unfortunately, no. Well, in a sense, yes, but it gets complicated fast.

As Clay Shirky put it aptly in the TED talk referenced in my introduction to this project, "computers are notoriously inflexible." Computers are really good a processing code. But if that code is not correct, they are really bad at figuring out what the programer meant to put there. And here we have the first hurdle to organizing a team to work on a document this large: code is processed in a linear fashion. Yes, it is in essence a giant document made up of text, but each of those chunks of code depends on other chunks to function. If someone gets into the code and makes some changes that cause that chunk of code to fail at its foundational job, then everything on top of it will also fail. To carry this to the encyclopedia analogy, imagine that to get to any given entry you have to read the whole thing, in order. If you hit a typo you have to start reading over at the beginning. If the entry for "Apple" has a typo in it, then the entry for "Elephant" would be inaccessible, and the book would sometimes catch on fire. As it relates to organizing a team to work on this document we have a tricky situation. Because a team member can only handle so much on their plate, tasks still need to be split up. But you can't simply mash all of the product back together after everyone has done their work. You can't do this because the chunks taken out are actually directly dependent on one another, you can't always tell what's broken, and often if one thing is broken the whole program will crash. This dependence breaks the standard organizational structure we were inclined to use. This hurdle is also shared by the law. In Shirky's talk he presents a graph of the interdependency of different sections of the United States Tax Code. This is not code in the sense of an operating system like Linux, but it is code in the sense of the government as operating system I broke down before. It is the set of rules by which our system of taxation operates. Similar to Linux, a change to one piece can break another piece. The Tax Code is a very very long interdependent document. So is Linux. Updating both are more work than one person can handle.

Because of the above mentioned interdependencies there's also a massive coordination problem that arises when we try to organize and administer a team working on one of these documents. Now think about a house versus an encyclopedia. The encyclopedia, read in order, is the codebase. What the computer spits out after it reads the code is the program, that's a house. If you want a window in your house you should probably hire a contractor. That contractor will start by measuring the space into which a window is going to fit. Then the contractor goes away to build the window, and bring it back. And any decent contractor will expect some "roughing in" to get that window to sit in the right place, and properly perform its functions. In the case of a codebase, and luckily for the programers, they aren't stuck with a house they have to travel to in order to double check the window. They are still dealing with a house though. That is to say, as work goes on changes need to be made, and those changes need to be checked against the dependencies before a finished product can be declared. Because it isn't a house, and a codebase is simply a text document so programers can take the house with them. This is a bonus, but it also gets us to the second hurdle: a coordination problem. Now imagine a thousand copies of the same house all with the empty space meant for a window, and each copy has a different contractor. Each contractor will install their window, in their copy of the house, at which point you get to tour all of them, pick the window you want, and then just live in that house like you always lived there. It's easy to imagine that the coordination of all of these contractors gets a bit messy when everyone has their own copy of the house, and they're working on more than windows, but lets just stick with the window for now. We need to get that window in there, everyone agrees on what a window looks like, and the basic function of the window, but there are many ways to skin that cat. You'll end up with some designs that make the hole smaller to fit one type of window, others that commit to a larger window, windows that open out, slide up, and so on. Each of those window designs, of course, having an impact on other things like airflow through the house, what can go in the yard outside the window, how much wall space there will be left to paint, so on and so on once again. Little tweaks here and there, the "roughing in" that needs to happen after everyone gets their window built. Now all thousand people who took their copy of the house off to work come back with their different fixes and tweaks to other parts to make those fixes work, and what do you have? Not an encyclopedia, and maybe not even a house if the changes were all extreme enough. Now you have a thousand different options for possible solutions to the initial problem "we need a window here." Again, here is where it makes sense that laws are called codes, as they again have in common this coordination problem. The laws need to be freely accessible, so everyone can read them and follow them. And as we begin to let our system of government chug along everyone has their ideas for how to fix the laws. Every team, made up of representatives and their staffers listens to some of those ideas, maybe forms their own, then takes their copy and goes off to work to get that idea in there. And they have exactly the same problem. Everyone comes back with their various different solutions, and all of the "roughing in" that it takes to make the solution fit. Lucky for contractors, wood is forgiving. Laws are as unforgiving as computer code. The leeway for "roughing in" is minimal before a typo in the entry for "Apple" breaks the entry for "Elephant."Interdependency and coordination are not problems unique to any of these situations, they are the reasons for any sort of hierarchical organizational structure. These struggles are the reason that governments are so large, and companies like Microsoft are so big. The larger the organizational diagram gets in order to mitigate the effect of these hurdles, the more managers are needed to keep everything from breaking. 

Now let's introduce another quirk that will help us understand the evolution of the tools to which this is an extended introduction: the open source movement. The "source" in open source refers to the code. The code underlying a program, which I have to this point called the "codebase" is sometimes called the source code. The "open" source model is a model of software development in which the source code for a piece of software is publicly available. Anyone can download the code, anyone can modify this code, and anyone who does so agrees to a license which stipulates that their work will also be public and freely edited by anyone else agreeing to the same "open" license. This model exists in opposition to a "closed" source model, which is that favored by anyone or any company who wants to keep their software proprietary. Closed software is more easily leveraged for profit, sometimes for security. Regardless of the motivation for an open versus closed model, the open model increases the difficulty brought about by the problems of interdependency and coordination by factors. Imagine all of the struggles I mentioned above, but in an open system. Take away the management gatekeeper that might oversee the large and complicated system required to keep all of this dependency and coordination from cascading into full on failure. Now not only are we looking at those two problems, but we just invited anyone interested to hop onboard with their edits, with their input. Sounds crazy, right? Sounds like an unmanageable mess, right? Well, we have this movement to thank for the tools that I hope we can now turn toward government to make our system truly one of the people. People like Linus Torvalds, the programer who started Linux (and from which it draws its name,) believed that open source, and massive collaboration on complicated projects would be the best way to facilitate projects of the scale needed for the advancement of technology. Software needed to be democratic, development of the software needed to be decentralized. In the face of the extent to which all of seems so difficult to manage, the open source movement took hold and ultimately this same movement developed the tools it needed to let itself persist. Tools like Git, and Stack Overflow.

##Git

Faced with the difficulties and complications mentioned above the open source programers, instead of abandoning the effort, built tools to help solve these problems. The first of these was a program called "Git." Git is what we call a "version control system." Broken down, that's quite literally a system by which all of the different versions of a codebase that have been checked out to be worked on, like we talked about above, are controlled. Git was literally developed by the same people that were working on Linux because they saw a looming coordination crisis as numbers grew, and maintenance of a stable codebase via email was increasingly difficult. They had used similar systems before buckling down to build Git, but most of them were costly, and still suffered from a degree of lag in coordination that made it difficult for multiple to people to work simultaneously. Part of the concern was not just that coordination is handled, but that collaborative effort is maximized. In a movement like the open source movement you have a lot of people working for free, simply because think they can help or they want to test out an idea at a solution for a problem noted by another user. When people are working for free, burning their time with inefficiency is foolish, and will reduce willingness to participate. Git was built with this in mind, and works through a "repository" system.  A repository, or a "repo," is a folder that contains everything you need to run the program. The main code, subfiles, etc. When running Git, any change made to a repo is given a unique identifier, and this ID is recorded in a .git file, which is included with everything else. This means the ID ledger is downloaded by anyone else who copies the repo. When software is open source anyone can also freely make a copy of the full repo, they call this "forking", or they can start their own "branch" of changes. Each of those count as a change, get their own identifier, and are recorded in the repo. As a program continues to take shape, and code is added, removed, written, and rewritten, every single set of edits gets its own ID, and all of this is included in the repo. When using a version control system a repo is ultimately not just a giant document with thousands of pages of code like I described above, but it is also a canonical record of every change that has ever been made to that code base and which programer, or team, made that change. In that sense it is the code as well as the history of every state in which that code has ever existed. You can see from the terminology used, words like "fork" and "branch" it is almost easier to visualize a codebase using Git as more of a tree than a long long document. Each change is a branch. A repo is not just a program, but a record of all the decisions and work that got the team to the final product. 

When it comes to coordination and collaboration the use of a version control system has a number of benefits. To begin with, many people can work on the same codebase without catastrophically breaking anything, while still giving them the access they need to the whole interdependent system to make sure nothing will break. They can fork the whole codebase, run the program, make their changes, and see if it still works, all on their own computer, not editing the master repo they made the copy off of. If it doesn't work they can keep working at fixing it, if it does they can submit these edits. This is called a "commit," I mentioned them before. This means the edits have been added to the Git ID ledger. After this those edits can be submitted to the main branch to be added to the "master" repo. Because the system is based not around full code documents, and instead around changes, things can happen much faster. The system is able to identify only the places where the code is now different, and present those changes to a manager, usually a "lead programer" who okays them to go into the main codebase. Instead of having to send the whole document back to the lead programer, the only thing that shows up, in a view where it's quite easy to see the changes, are the changes themselves. The lead programer can then add those to the main codebase with a single click. Everyone else working on other changes will see no difference on their fork until they sync to the main repo. Once they sync they have the new master repo code, and can get back to editing without worrying about breaking the master codebase. This is the first big benefit: by tracking changes instead of completed documents, the amount of information that needs to be sent back and forth is considerably decreased. All that needs to be sent is the tracking data, and the changes, instead of a whole, now different, copy of the program. Next the canonical nature of the version tracking makes it so that the code is forever backed up. Here it helps to imagine the tree structure I alluded to earlier. If the lead programer checks out all the changes, and they seem good in theory, but in practice they break the program, fixing it is as simple as backing up to the last fork in the tree. Before the changes were committed to the codebase, and broke the whole thing. Because the repo is not just the program, but the record of all the changes ever made, we can just back up to the last place the program functioned, and try again. The ability to do this also facilitates massive collaboration on other levels. With so many people working on a project there are bound to be conflicts, the ability to simply go back in time to before a conflict broke things is important, and easily facilitated by version control software like Git. What's more, each of the changes can be associated with the person who made that change. This means that a team member who regularly submits changes that don't work can be identified, helped, or, worst case, dismissed from the project. Luckily, with the ability to roll back errors so easily, learning how to improve as a programer becomes much more about practice, and much less about theory.

##Github

The powers of a tool like Git collided with the notions of openness born of the open source movement and the result was the "open repository" or "public repo" and tools like Github. While the functions of Git and similar version control systems allow large numbers of programers to work on a project at the same time, there is no inbuilt function for sharing. A repo might be hosted only on a company's local server, with the company's programers using Git to coordinate changes. That repo might even have an address where anyone can access the code if they know that address. But there is no inherent capacity of Git that makes the repository "open." This is a question of how to share a repo to really make it open, in line with Open Source kind of open. In came Github (and similar services.) Github is a web based repository hosting service, and has grown into a sort of social network of programers. Github facilitates the sharing of open source documents by providing a degree of centralization. It does not centralize in the sense of control mechanisms described in the earlier chapter, there is no control over the programing that takes place. Rather Github is a service providing a set of parameters for hosting and sharing repositories. In that way it functions more like a town square. Github provides free accounts which allow anyone to host a certain number of public repositories. The public nature of these repos means that anyone can fork, and then work on the code same as above. They can then submit those changes and the host can choose to incorporate the changes. With a paid account on Github a programer can host private repos, for which an invite is required. I have a Github account (you can look it up, @thekerp) and although I don't know in what form you may be encountering this piece, early versions of this very writing were hosted on Github in an open repo. When working within a Github repo all changes made, and tracked via the Git dynamic discussed above, are tied to a user's Github account. In essence Github puts a social layer on top of the coordination tool that is Git. (This idea of layering will continue to come up. Keep it in mind.) Github draws the power of Git out into the public space, and invites anyone to play. Not only does this democratize the ability to have an impact on the shape of the programs hosted in any given public repo, but it even further facilitates and democratizes the chance to learn and improve. Git, with a layer like Github on top begins to become the embodiment of "the marketplace of ideas" so tightly tied to the First Amendment to the US Constitution. In a world of open repositories good code stays, bad code is weeded out. 

It is easy to see how a version of such a system might carry over to the realm of lawmaking, or even law in general. In fact the extent to which version control should be used for iteration in law writing makes the topic almost boring. Laws should be kept in repos, and a Git-like system should be used to track the history of changes made to the bill or law. This should all be hosted in a Github like structure providing access to any United States citizen, and hell, might as well let them fork the repos if they want. Who knows what they might write. So what happens when a system like Git removes the burden of coordination and collaboration? Even more new and interesting tools begin to emerge. New and interesting dynamics begin to emerge. As discussed, laws are quite similar to code, and certainly suffer from the same problems of coordination when working with a large team. Historically the answer to the problems of coordination have been to limit the size of the team. Pick a representative, and let that person pick a "manageable" number of people to work on drafting a law. If we stop trying to make that team manageable, and we open team membership to anyone who wants to be involved, interesting things happen. In the realm of programming those interesting things are the result of the very last notion in the paragraph above. The ability to roll back errors begets the ability to try and fail, begets the ability to learn by doing. This in turn opens a void where those with resources enough to take a shot at coding are looking for the answers to their questions. Now we have a new problem, for which the world of massively collaborating programers also devised a solution. One that might again have implications for a system of lawmaking.

## Stack Overflow

Tools like Git, and Github not only open up a world in which large scale collaboration on programs as vast as Linux are possible, but also reduce the barrier to entry. In an open source repo the code is freely accessible, and version control allows you not only to keep up with the work of others, but to compare the work of others. To easily incorporate the work of others. And maybe most importantly, try and fail without consequence. Add in that you can write code with the most basic of computers, and you have a perfect scenario for education. It is difficult to learn to build a house, you have to leave a trail of poorly hewn boards in your wake. This gets expensive. When working on a version controlled program you can catastrophically wreck the codebase and simply roll back to the last time that it worked. You can truly learn by doing, a loss of time as your only consequence. Because of this there has sprung up a whole host of tools to help with learning and to help with problem solving. In addition to resources like the now ubiquitous Wikipedia, numerous question and answer sites have sprung up solely to connect people with very specific questions to people who have the answers, and are willing to take the time to explain. Such sites seem most frequently used to convince the general population that they are dying of some disease (Yahoo Answers, I'm looking at you,) but mostly they fill in the gaps where broader resources like Wikipedia do not have the answers. Stack Overflow sprung up to fill the programming gap.

Stack Overflow is named for a software error in which a variable is bigger, in terms of characters, than the space it is meant to occupy. It's usually caused by some sort of accidental recursive operation that if allowed to run keeps adding to a variable until that number is so large there aren't enough characters allocated to keep it in memory. Stack Overflow, the site, is actually a question and answer website devoted to the broad topic of computer programming. Loosely I would guess that the name was pulled from the frustration of running into something like a stack overflow, and the desire to ask someone for help if you are unable to solve it. More likely the name was chosen because it sounds cool. Regardless, the website has a number of features that have made it a remarkable resource for programming knowledge. Stack Overflow was certainly not the first question and answer site to pop up, or even the first devoted to programming, but the creators of Stack Overflow added a few unique features. First, answers, and questions, can be voted on by users. This means that the most common questions, and the most clear questions, rise to the top. Additionally, the answers to the questions end up sorted by which answer is the correct solution to the question. Second, there is a "reputation" system. This system awards points to the writer's profile for up votes on both questions and on answers. Users of Stack Overflow end up with reputation rankings based on both how well they ask questions, and answer them. As a user climbs in reputation they are also given increased permissions and responsibilities within the community. This means they gain ability to edit questions, delete answers, and so on. Included is the ability to close out a question. This is the final feature unique to Stack Overflow. When a question has a satisfactory answer, that is, the solution provided fixes the problem, then the question is closed. It remains in the system, so it shows up in search, but there is no longer any voting. As a resource this answer is considered a functional solution to the problem. Over time this system has created an extremely useful resource on a number of levels. Often you don't even have to submit a question anymore, a simple search will turn up where it's already been asked and answered. Not only are most questions one might have with regards to programming likely already answered somewhere on Stack, but you can look at a programers reputation number to get a decent sense of their standing on the cutting edge of programming. I say the cutting edge because there's no chance to gain points answering the old questions, so points are picked up these days answering and posting new questions in the topics where people are doing new things. 

It is difficult to say which of these features of Stack Overflow only function as they do because of the finite nature of a programming solution (that is, because a solution in code either works or doesn't) and which features might be applicable elsewhere. For my purposes Stack Overflow serves as an example not just of an interesting byproduct of the open source movement, and the massive collaboration facilitated by version control software, but as an example of what I call a "merit layer." Specifics aside, Stack Overflow, much like Reddit, has added a merit layer to simple question and answer. One could even argue that there are multiple merit layers. Layer one: the questions and answers are voted on, layer two: those votes result in reputation points. This merit layer is of particular interest in the realm of democracy. Because the idea of merit is inextricably intertwined with any system in which voting takes place. When we vote for a representative we are ascribing merit to the ideas they are expressing as they campaign for the position. We are electing them to take the office of representative, but beyond that we are at least in theory, electing them to execute on the ideas they told us they would. Stack Overflow is an example of how we can, at the the scale of massive communication on the internet, find ways to build in merit layers.

There is no reason a single election, or maybe public protest need be the only means by which we ascribe merit to the ideas and the performance of our chosen delegates, and the laws they try to enact. When we look at a system of version control, a system where every change is tracked, and every change is linked to the person that made that change, it is very easy to see where merit layers might be installed. In the world of modern communication there is little excuse for the reality that our ability as a population to have an effect on the actions of our government stops with a periodic chance to replace our representatives, once again hoping that they stick to their word, or deliver on promises. With the tools that already exist there are fewer and fewer hurdles standing in the way of a system of government more "of the people" than we have ever seen. A government in which transparency reigns supreme, in which a politician's record is accessible as a version control backlog. A government in which their ability to carry out their promises, their ability to write effective laws, and their ability to collaborate to make those laws workable is quantified via merit layers. There is no reason our politicians cannot have a score next to their name by which we are able to ascertain their merit as lawmakers, and as leaders. 

